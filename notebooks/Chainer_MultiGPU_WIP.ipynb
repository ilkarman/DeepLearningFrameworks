{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Create a data-augmentor + data-preprocessing class\n",
    "# Using cv2 not pil and maybe using https://github.com/aleju/imgaug\n",
    "# Will ensure that pre-processing + augmentation standardised across frameworks\n",
    "# Also maybe PIL is bottlenecking pytorch?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chainer\n",
    "import chainer.functions as F\n",
    "import chainer.links as L\n",
    "from chainer import optimizers, cuda, dataset, training\n",
    "from chainer.training import extensions, updaters, StandardUpdater\n",
    "from chainer.dataset import concat_examples\n",
    "from chainer.links import ResNet50Layers\n",
    "from sklearn.metrics.ranking import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from PIL import Image\n",
    "import random\n",
    "import cv2\n",
    "from common.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance Improvement\n",
    "# 1. Auto-tune\n",
    "# This adds very little now .. not sure if True by default?\n",
    "chainer.global_config.autotune = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.5.2 |Anaconda custom (64-bit)| (default, Jul  2 2016, 17:53:06) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "Chainer:  3.4.0\n",
      "CuPy:  2.4.0\n",
      "Numpy:  1.14.1\n",
      "GPU:  ['Tesla P100-PCIE-16GB', 'Tesla P100-PCIE-16GB']\n",
      "CUDA Version 8.0.61\n",
      "CuDNN Version  6.0.21\n",
      "CPUs:  12\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Chainer: \", chainer.__version__)\n",
    "print(\"CuPy: \", chainer.cuda.cupy.__version__)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())\n",
    "CPU_COUNT = multiprocessing.cpu_count()\n",
    "print(\"CPUs: \", CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-set\n",
    "# Note if NUM_GPUS > 1 then MULTI_GPU = True and ALL GPUs will be used\n",
    "# Set below to affect batch-size\n",
    "# E.g. 1 GPU = 64, 2 GPUs = 64*2, 4 GPUs = 64*4\n",
    "# Note that the effective learning-rate will be decreased this way\n",
    "NUM_GPUS = 1 # Scaling factor for batch\n",
    "MULTI_GPU=NUM_GPUS>1\n",
    "DEVICES=tuple([0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globals\n",
    "CLASSES = 14\n",
    "WIDTH = 224\n",
    "HEIGHT = 224\n",
    "CHANNELS = 3\n",
    "LR = 0.0001  # Effective learning-rate will decrease as BATCHSIZE rises\n",
    "EPOCHS = 5\n",
    "BATCHSIZE = 64*NUM_GPUS\n",
    "IMAGENET_RGB_MEAN =  np.array([0.485, 0.456, 0.406], dtype=np.float32)\n",
    "IMAGENET_RGB_SD =  np.array([0.229, 0.224, 0.225], dtype=np.float32)\n",
    "TOT_PATIENT_NUMBER = 30805  # From data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chestxray/images chestxray/Data_Entry_2017.csv\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "CSV_DEST = \"chestxray\"\n",
    "IMAGE_FOLDER = os.path.join(CSV_DEST, \"images\")\n",
    "LABEL_FILE = os.path.join(CSV_DEST, \"Data_Entry_2017.csv\")\n",
    "print(IMAGE_FOLDER, LABEL_FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please make sure to download\n",
      "https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\n",
      "Data already exists\n",
      "CPU times: user 737 ms, sys: 285 ms, total: 1.02 s\n",
      "Wall time: 1.03 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Download data\n",
    "print(\"Please make sure to download\")\n",
    "print(\"https://docs.microsoft.com/en-us/azure/storage/common/storage-use-azcopy-linux#download-and-install-azcopy\")\n",
    "download_data_chextxray(CSV_DEST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XrayData(dataset.DatasetMixin):\n",
    "    def __init__(self, patient_ids, img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, augmentation=None):\n",
    "        # Read labels-csv\n",
    "        df = pd.read_csv(lbl_file)\n",
    "        \n",
    "        # Split labels on unfiltered data\n",
    "        df_label = df['Finding Labels'].str.split(\n",
    "            '|', expand=False).str.join(sep='*').str.get_dummies(sep='*')\n",
    "        \n",
    "        # Filter by patient-ids (both)\n",
    "        df_label['Patient ID'] = df['Patient ID']\n",
    "        df_label = df_label[df_label['Patient ID'].isin(patient_ids)]\n",
    "        df = df[df['Patient ID'].isin(patient_ids)]\n",
    "        \n",
    "        # Remove unncessary columns\n",
    "        df_label.drop(['Patient ID','No Finding'], axis=1, inplace=True)  \n",
    "        \n",
    "        # List of images (full-path)\n",
    "        self.img_locs =  df['Image Index'].map(lambda im: os.path.join(img_dir, im)).values\n",
    "        # One-hot encoded labels (float32 for BCE loss)\n",
    "        self.labels = df_label.values\n",
    "        \n",
    "        # Processing\n",
    "        self.augmentation = augmentation\n",
    "        print(\"Loaded {} labels and {} images\".format(len(self.labels), len(self.img_locs)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_locs)   \n",
    "    \n",
    "    def get_example(self, idx):\n",
    "        im_file = self.img_locs[idx]\n",
    "        # RGB Image\n",
    "        im = cv2.imread(im_file) \n",
    "        im_rgb = self._apply_data_preprocessing(im)\n",
    "        label = self.labels[idx]\n",
    "        if self.augmentation is not None:\n",
    "            im_rgb = self._apply_data_augmentation(im_rgb)\n",
    "        return np.array(im_rgb, dtype=np.float32), np.array(label, dtype=np.int32)\n",
    "    \n",
    "    def _apply_data_preprocessing(self, im, w=WIDTH, h=HEIGHT, \n",
    "                                  rgb_m=IMAGENET_RGB_MEAN, rgb_sd=IMAGENET_RGB_SD):\n",
    "        # REDO Method!\n",
    "        # BGR to RGB\n",
    "        im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB) \n",
    "        # Resize\n",
    "        im = cv2.resize(im, dsize=(w, h), interpolation=cv2.INTER_CUBIC)\n",
    "        # Channels first (3, 224, 224)\n",
    "        im = np.moveaxis(im, -1, 0)\n",
    "        # Normalise image with imagenet-values\n",
    "        # This is torch-model normalisation\n",
    "        # Ref: https://github.com/keras-team/keras/blob/master/keras/applications/imagenet_utils.py\n",
    "        im = im / 255.\n",
    "        im = (im - rgb_m[:, None, None]) / rgb_sd[:, None, None]\n",
    "        return im\n",
    "    \n",
    "    def _apply_data_augmentation(self, im):\n",
    "        # REDO Method!\n",
    "        # Random horizontal flip\n",
    "        if random.randint(0, 1):\n",
    "            im = cv2.flip(im, flipCode=1)\n",
    "        # Random rotation\n",
    "        # ...\n",
    "        # Random crop/zoom\n",
    "        # ...\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:21563 valid:3080 test:6162\n"
     ]
    }
   ],
   "source": [
    "# Training / Valid / Test split (70% / 10% / 20%)\n",
    "train_set, other_set = train_test_split(\n",
    "    range(1,TOT_PATIENT_NUMBER+1), train_size=0.7, test_size=0.3, shuffle=False)\n",
    "valid_set, test_set = train_test_split(other_set, train_size=1/3, test_size=2/3, shuffle=False)\n",
    "print(\"train:{} valid:{} test:{}\".format(\n",
    "    len(train_set), len(valid_set), len(test_set)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 87306 labels and 87306 images\n",
      "Loaded 7616 labels and 7616 images\n",
      "Loaded 17198 labels and 17198 images\n"
     ]
    }
   ],
   "source": [
    "train_dataset = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=train_set, augmentation=True)\n",
    "valid_dataset = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=valid_set, augmentation=False)\n",
    "test_dataset  = XrayData(img_dir=IMAGE_FOLDER, lbl_file=LABEL_FILE, patient_ids=test_set, augmentation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class chexnet(ResNet50Layers):\n",
    "    \n",
    "    def __init__(self, pretrained_model=\"auto\", basemodel_out='pool5', out_features=CLASSES):\n",
    "        super(chexnet, self).__init__(pretrained_model)\n",
    "        self._basemodel_out = basemodel_out\n",
    "        in_features = 2048\n",
    "        with self.init_scope():\n",
    "            self.classifier = L.Linear(in_features, out_features)\n",
    "    \n",
    "    def __call__(self, x, **kwargs):\n",
    "        h = super(chexnet, self).__call__(x, layers=[self._basemodel_out], **kwargs)[self._basemodel_out]\n",
    "        h = self.classifier(h)\n",
    "        #return F.sigmoid_cross_entropy(h, t)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbol(model_name='densenet121'):\n",
    "    if model_name == 'resnet50':\n",
    "        m = chexnet()\n",
    "    elif model_name == 'densenet121':\n",
    "        # https://github.com/chainer/chainer/issues/4426\n",
    "        raise ValueError(\"Densenet is not yet officially implemented in Chainer\")\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model-name\")\n",
    "    # CUDA\n",
    "    chainer.cuda.get_device(0).use()  # Make a specified GPU current\n",
    "    m.to_gpu()  \n",
    "    return m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_symbol(sym, lr=LR):\n",
    "    opt = optimizers.Adam(alpha=lr, beta1=0.9, beta2=0.999)\n",
    "    opt.setup(sym)\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roc_auc(data_gt, data_pd, full=True, classes=CLASSES):\n",
    "    roc_auc = []\n",
    "    for i in range(classes):\n",
    "        roc_auc.append(roc_auc_score(data_gt[:, i], data_pd[:, i]))\n",
    "    print(\"Full AUC\", roc_auc)\n",
    "    roc_auc = np.mean(roc_auc)\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lossfun(x, t):\n",
    "    return F.sigmoid_cross_entropy(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 834 ms, sys: 336 ms, total: 1.17 s\n",
      "Wall time: 1.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load symbol\n",
    "predictor = get_symbol(model_name='resnet50')\n",
    "chexnet_sym = L.Classifier(predictor, lossfun=lossfun)\n",
    "chexnet_sym.compute_accuracy = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 608 µs, sys: 131 µs, total: 739 µs\n",
      "Wall time: 747 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load optimiser\n",
    "optimizer = init_symbol(chexnet_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data-iterators\n",
    "# Open-CV runs on GPU by default!\n",
    "# Weird-bug to set shared_mem\n",
    "\n",
    "#train_iters = [\n",
    "#    chainer.iterators.MultiprocessIterator(\n",
    "#        train_dataset, BATCHSIZE, shared_mem=700000, n_prefetch=10, n_processes=CPU_COUNT) \n",
    "#    for i in chainer.datasets.split_dataset_n_random(train_dataset, len(DEVICES))]\n",
    "\n",
    "train_iter = chainer.iterators.MultiprocessIterator(\n",
    "    train_dataset, BATCHSIZE, shared_mem=700000, n_prefetch=10, n_processes=CPU_COUNT)\n",
    "valid_iter = chainer.iterators.MultiprocessIterator(\n",
    "    valid_dataset, BATCHSIZE, shared_mem=700000, repeat=False, shuffle=False, n_prefetch=10, n_processes=CPU_COUNT)\n",
    "test_iter = chainer.iterators.MultiprocessIterator(\n",
    "    test_dataset, BATCHSIZE, shared_mem=700000, repeat=False, shuffle=False, n_prefetch=10, n_processes=CPU_COUNT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultiprocessParallelUpdater requires NCCL.\n",
    "# https://github.com/nvidia/nccl#build--run\n",
    "#updater = updaters.MultiprocessParallelUpdater(train_iters, optimizer, devices=DEVICES)\n",
    "\n",
    "updater = StandardUpdater(train_iter, optimizer, device=0)\n",
    "val_interval = (1, 'epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = training.Trainer(updater, stop_trigger=(EPOCHS, 'epoch'))\n",
    "trainer.extend(extensions.Evaluator(valid_iter, chexnet_sym, device=DEVICES[0]), trigger=val_interval)\n",
    "trainer.extend(extensions.snapshot(), trigger=val_interval)\n",
    "# Save log to disk\n",
    "trainer.extend(extensions.LogReport(trigger=val_interval))\n",
    "trainer.extend(extensions.PlotReport(['main/loss', 'validation/main/loss'], x_key='epoch', file_name='loss.png'))\n",
    "trainer.extend(extensions.observe_lr(), trigger=val_interval)\n",
    "trainer.extend(extensions.PrintReport([\n",
    "    'epoch', 'iteration', 'main/loss', 'validation/main/loss', 'lr']), trigger=val_interval)\n",
    "trainer.extend(extensions.ProgressBar(update_interval=500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[J     total [###...............................................]  7.33%\n",
      "this epoch [##################................................] 36.65%\n",
      "       500 iter, 0 epoch / 5 epochs\n",
      "       inf iters/sec. Estimated time to finish: 0:00:00.\n",
      "\u001b[4A\u001b[J     total [#######...........................................] 14.66%\n",
      "this epoch [####################################..............] 73.31%\n",
      "      1000 iter, 0 epoch / 5 epochs\n",
      "    3.1824 iters/sec. Estimated time to finish: 0:30:29.037217.\n",
      "\u001b[4Aepoch       iteration   main/loss   validation/main/loss  lr        \n",
      "\u001b[J1           1365        0.162315    0.146133              8.63014e-05  \n",
      "\u001b[J     total [##########........................................] 21.99%\n",
      "this epoch [####..............................................]  9.96%\n",
      "      1500 iter, 1 epoch / 5 epochs\n",
      "    2.8743 iters/sec. Estimated time to finish: 0:30:51.150733.\n",
      "\u001b[4A\u001b[J     total [##############....................................] 29.32%\n",
      "this epoch [#######################...........................] 46.61%\n",
      "      2000 iter, 1 epoch / 5 epochs\n",
      "    2.9701 iters/sec. Estimated time to finish: 0:27:03.113358.\n",
      "\u001b[4A\u001b[J     total [##################................................] 36.65%\n",
      "this epoch [#########################################.........] 83.26%\n",
      "      2500 iter, 1 epoch / 5 epochs\n",
      "    3.0204 iters/sec. Estimated time to finish: 0:23:50.520224.\n",
      "\u001b[4A\u001b[J2           2729        0.148824    0.143283              9.66853e-05  \n",
      "\u001b[J     total [#####################.............................] 43.98%\n",
      "this epoch [#########.........................................] 19.92%\n",
      "      3000 iter, 2 epoch / 5 epochs\n",
      "    2.9323 iters/sec. Estimated time to finish: 0:21:42.999741.\n",
      "\u001b[4A\u001b[J     total [#########################.........................] 51.31%\n",
      "this epoch [############################......................] 56.57%\n",
      "      3500 iter, 2 epoch / 5 epochs\n",
      "    2.9712 iters/sec. Estimated time to finish: 0:18:37.667800.\n",
      "\u001b[4A\u001b[J     total [#############################.....................] 58.64%\n",
      "this epoch [##############################################....] 93.22%\n",
      "      4000 iter, 2 epoch / 5 epochs\n",
      "    2.9996 iters/sec. Estimated time to finish: 0:15:40.390953.\n",
      "\u001b[4A\u001b[J3           4093        0.142471    0.141806              9.91638e-05  \n",
      "\u001b[J     total [################################..................] 65.97%\n",
      "this epoch [##############....................................] 29.87%\n",
      "      4500 iter, 3 epoch / 5 epochs\n",
      "    2.9514 iters/sec. Estimated time to finish: 0:13:06.339690.\n",
      "\u001b[4A\u001b[J     total [####################################..............] 73.31%\n",
      "this epoch [#################################.................] 66.53%\n",
      "      5000 iter, 3 epoch / 5 epochs\n",
      "    2.9753 iters/sec. Estimated time to finish: 0:10:11.957355.\n",
      "\u001b[4A\u001b[J4           5457        0.135639    0.141937              9.9787e-05  \n",
      "\u001b[J     total [########################################..........] 80.64%\n",
      "this epoch [#.................................................]  3.18%\n",
      "      5500 iter, 4 epoch / 5 epochs\n",
      "    2.9406 iters/sec. Estimated time to finish: 0:07:29.154214.\n",
      "\u001b[4A\u001b[J     total [###########################################.......] 87.97%\n",
      "this epoch [###################...............................] 39.83%\n",
      "      6000 iter, 4 epoch / 5 epochs\n",
      "     2.961 iters/sec. Estimated time to finish: 0:04:37.200355.\n",
      "\u001b[4A\u001b[J     total [###############################################...] 95.30%\n",
      "this epoch [######################################............] 76.49%\n",
      "      6500 iter, 4 epoch / 5 epochs\n",
      "    2.9782 iters/sec. Estimated time to finish: 0:01:47.711002.\n",
      "\u001b[4A\u001b[J5           6821        0.127497    0.144582              9.99456e-05  \n",
      "\u001b[JCPU times: user 31min 3s, sys: 7min, total: 38min 3s\n",
      "Wall time: 38min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# 1 GPU = 3.1864 iters/sec\n",
    "# Wall time: 38min 30s\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################################################\n",
    "## Test CheXNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can load model from checkpoint\n",
    "#model = MyNetwon_samplesrk()\n",
    "# Load the saved paremeters into the instance\n",
    "#serializers.load_npz('my_mnist.model', model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23.9 s, sys: 6.8 s, total: 30.7 s\n",
      "Wall time: 39.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_truth = test_dataset.labels\n",
    "y_guess = []\n",
    "test_iter.reset()\n",
    "with chainer.using_config('train', False), chainer.using_config('enable_backprop', False):\n",
    "    for test_batch in test_iter:\n",
    "        # Data\n",
    "        x_test, y_test = concat_examples(test_batch, device=DEVICES[0])\n",
    "        # Prediction (need to apply sigmoid to turn into probability)\n",
    "        pred = cuda.to_cpu(F.sigmoid(predictor(x_test)).data)\n",
    "        # Collect results\n",
    "        y_guess.append(pred)           \n",
    "# Concatenate\n",
    "y_guess = np.concatenate(y_guess, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full AUC [0.7959918830854983, 0.8676733044046839, 0.7920831546814132, 0.8865145508302182, 0.8728580733365436, 0.9080358863148836, 0.6863813659372562, 0.8018957515812862, 0.6258983693447457, 0.8333604967695744, 0.7259107622516274, 0.7699872046546715, 0.7452577957897106, 0.8783915675050874]\n",
      "Test AUC: 0.7993\n"
     ]
    }
   ],
   "source": [
    "# Test AUC: 0.7993\n",
    "print(\"Test AUC: {0:.4f}\".format(compute_roc_auc(y_truth, y_guess)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
