{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MXNet/Gluon Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd\n",
    "from collections import namedtuple\n",
    "from common.params_inf import *\n",
    "from common.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force one-gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OS:  linux\n",
      "Python:  3.6.3 |Anaconda custom (64-bit)| (default, Oct 13 2017, 12:02:49) \n",
      "[GCC 7.2.0]\n",
      "Numpy:  1.13.3\n",
      "GPU:  ['Tesla V100-SXM2-16GB']\n",
      "CUDA Version 9.0.176\n",
      "CuDNN Version  7.0.5\n"
     ]
    }
   ],
   "source": [
    "print(\"OS: \", sys.platform)\n",
    "print(\"Python: \", sys.version)\n",
    "print(\"Numpy: \", np.__version__)\n",
    "print(\"GPU: \", get_gpu_name())\n",
    "print(get_cuda_version())\n",
    "print(\"CuDNN Version \", get_cudnn_version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch = namedtuple('Batch', ['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1280, 224, 224, 3) (1280, 3, 224, 224)\n"
     ]
    }
   ],
   "source": [
    "# Create batches of fake data\n",
    "fake_input_data_cl, fake_input_data_cf = give_fake_data(BATCH_SIZE*BATCHES_GPU)\n",
    "print(fake_input_data_cl.shape, fake_input_data_cf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded\n"
     ]
    }
   ],
   "source": [
    "# Download Resnet weights\n",
    "path='http://data.mxnet.io/models/imagenet/'\n",
    "mx.test_utils.download(path+'resnet/50-layers/resnet-50-symbol.json')\n",
    "mx.test_utils.download(path+'resnet/50-layers/resnet-50-0000.params')\n",
    "print(\"Downloaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "sym, arg_params, aux_params = mx.model.load_checkpoint('resnet-50', 0)\n",
    "# List the last 10 layers\n",
    "all_layers = sym.get_internals()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Symbol group [bn1_moving_var, bn1, relu1, pool1, flatten0, fc1_weight, fc1_bias, fc1, softmax_label, softmax]>\n"
     ]
    }
   ],
   "source": [
    "print(all_layers[len(all_layers)-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get last layer\n",
    "flatten_layer = all_layers['flatten0_output']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create the network\n",
    "net = gluon.nn.SymbolBlock(outputs=flatten_layer, inputs=mx.sym.var('data'))\n",
    "ctx = mx.gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We assign the weights\n",
    "net_params = net.collect_params()\n",
    "for param in arg_params:\n",
    "    if param in net_params:\n",
    "        net_params[param]._load_init(arg_params[param], ctx=ctx)\n",
    "for param in aux_params:\n",
    "    if param in net_params:\n",
    "        net_params[param]._load_init(aux_params[param], ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We hybridize the network\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(classifier, data, batchsize):\n",
    "    \"\"\" Return features from classifier \"\"\"\n",
    "    out = nd.zeros((len(data), RESNET_FEATURES), dtype=np.float32)\n",
    "    for idx, dta in yield_mb_X(data, batchsize):\n",
    "        outputs = classifier(mx.nd.array(dta, ctx=ctx))\n",
    "        out[idx*batchsize:(idx+1)*batchsize] = outputs\n",
    "    nd.waitall()\n",
    "    return out.asnumpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "cold_start = predict_fn(net, fake_input_data_cf, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.46 s, sys: 424 ms, total: 1.88 s\n",
      "Wall time: 1.39 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features = predict_fn(net, fake_input_data_cf, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images per second 920.8633093525181\n"
     ]
    }
   ],
   "source": [
    "print(\"Images per second {}\".format((BATCH_SIZE*BATCHES_GPU)/1.39))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
